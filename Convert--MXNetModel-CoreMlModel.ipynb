{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This document serve as a tutorial to show how to convert MXNet model to CoreMLModel \n",
    "# Target: image classification model\n",
    "# Require Libraries: mxnet, numpy, onnx_coreml, coremltools, copy, PIL\n",
    "\n",
    "#Reference Tutorial: \n",
    "# Convert to Onxx: https://mxnet.apache.org/api/python/docs/tutorials/deploy/export/onnx.html\n",
    "# Adding scale layer and normalized image: https://github.com/onnx/onnx-coreml/issues/338"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tomriddle/miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/tomriddle/miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/tomriddle/miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/tomriddle/miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/tomriddle/miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/tomriddle/miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/Users/tomriddle/miniconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/tomriddle/miniconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/tomriddle/miniconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/tomriddle/miniconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/tomriddle/miniconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/tomriddle/miniconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import mxnet as mx\n",
    "import numpy as np\n",
    "from mxnet.contrib import onnx as onnx_mxnet\n",
    "from onnx_coreml import convert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0317 20:30:52.791011 4724682048 _op_translations.py:660] Pooling: ONNX currently doesn't support pooling_convention. This might lead to shape or accuracy issues. https://github.com/onnx/onnx/issues/549\n"
     ]
    }
   ],
   "source": [
    "# Assume that you already have the trained model,\n",
    "# The trained model will be saved in two files: model.json and model_weight.params\n",
    "\n",
    "# First, we need to convert MXNet model to Onnx model (open neural network exchange)\n",
    "\n",
    "# Location of the model\n",
    "sym = './trained_models/myresnet_cat-symbol.json'\n",
    "params = './trained_models/myresnet_cat-0010.params'\n",
    "\n",
    "# The shape of the image is: 224 x 224\n",
    "input_shape = (1,3,224,224)\n",
    "onnx_file = 'myresnet_cat.onnx'\n",
    "\n",
    "#convert to onnx\n",
    "converted_model_path = onnx_mxnet.export_model(sym, params, [input_shape], np.float32, onnx_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "# Image scale for ImageNet\n",
    "\"\"\"\n",
    "IMAGE_NET_MEAN = [0.485, 0.456, 0.406]\n",
    "IMAGE_NET_STD = [0.229, 0.224, 0.225]\n",
    "\"\"\"\n",
    "scale = 1.0 / (0.226 * 255.0)\n",
    "red_scale = 1.0 / (0.229 * 255.0)\n",
    "green_scale = 1.0 / (0.224 * 255.0)\n",
    "blue_scale = 1.0 / (0.225 * 255.0)\n",
    "\n",
    "args = dict(is_bgr=False, red_bias = -(0.485 * 255.0) * red_scale  , green_bias = -(0.456 * 255.0) * green_scale,\n",
    "            blue_bias = -(0.406 * 255.0) * blue_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/175: Converting Node Type BatchNormalization\n",
      "2/175: Converting Node Type Conv\n",
      "3/175: Converting Node Type BatchNormalization\n",
      "4/175: Converting Node Type Relu\n",
      "5/175: Converting Node Type MaxPool\n",
      "6/175: Converting Node Type BatchNormalization\n",
      "7/175: Converting Node Type Relu\n",
      "8/175: Converting Node Type Conv\n",
      "9/175: Converting Node Type BatchNormalization\n",
      "10/175: Converting Node Type Relu\n",
      "11/175: Converting Node Type Conv\n",
      "12/175: Converting Node Type BatchNormalization\n",
      "13/175: Converting Node Type Relu\n",
      "14/175: Converting Node Type Conv\n",
      "15/175: Converting Node Type Conv\n",
      "16/175: Converting Node Type Add\n",
      "17/175: Converting Node Type BatchNormalization\n",
      "18/175: Converting Node Type Relu\n",
      "19/175: Converting Node Type Conv\n",
      "20/175: Converting Node Type BatchNormalization\n",
      "21/175: Converting Node Type Relu\n",
      "22/175: Converting Node Type Conv\n",
      "23/175: Converting Node Type BatchNormalization\n",
      "24/175: Converting Node Type Relu\n",
      "25/175: Converting Node Type Conv\n",
      "26/175: Converting Node Type Add\n",
      "27/175: Converting Node Type BatchNormalization\n",
      "28/175: Converting Node Type Relu\n",
      "29/175: Converting Node Type Conv\n",
      "30/175: Converting Node Type BatchNormalization\n",
      "31/175: Converting Node Type Relu\n",
      "32/175: Converting Node Type Conv\n",
      "33/175: Converting Node Type BatchNormalization\n",
      "34/175: Converting Node Type Relu\n",
      "35/175: Converting Node Type Conv\n",
      "36/175: Converting Node Type Add\n",
      "37/175: Converting Node Type BatchNormalization\n",
      "38/175: Converting Node Type Relu\n",
      "39/175: Converting Node Type Conv\n",
      "40/175: Converting Node Type BatchNormalization\n",
      "41/175: Converting Node Type Relu\n",
      "42/175: Converting Node Type Conv\n",
      "43/175: Converting Node Type BatchNormalization\n",
      "44/175: Converting Node Type Relu\n",
      "45/175: Converting Node Type Conv\n",
      "46/175: Converting Node Type Conv\n",
      "47/175: Converting Node Type Add\n",
      "48/175: Converting Node Type BatchNormalization\n",
      "49/175: Converting Node Type Relu\n",
      "50/175: Converting Node Type Conv\n",
      "51/175: Converting Node Type BatchNormalization\n",
      "52/175: Converting Node Type Relu\n",
      "53/175: Converting Node Type Conv\n",
      "54/175: Converting Node Type BatchNormalization\n",
      "55/175: Converting Node Type Relu\n",
      "56/175: Converting Node Type Conv\n",
      "57/175: Converting Node Type Add\n",
      "58/175: Converting Node Type BatchNormalization\n",
      "59/175: Converting Node Type Relu\n",
      "60/175: Converting Node Type Conv\n",
      "61/175: Converting Node Type BatchNormalization\n",
      "62/175: Converting Node Type Relu\n",
      "63/175: Converting Node Type Conv\n",
      "64/175: Converting Node Type BatchNormalization\n",
      "65/175: Converting Node Type Relu\n",
      "66/175: Converting Node Type Conv\n",
      "67/175: Converting Node Type Add\n",
      "68/175: Converting Node Type BatchNormalization\n",
      "69/175: Converting Node Type Relu\n",
      "70/175: Converting Node Type Conv\n",
      "71/175: Converting Node Type BatchNormalization\n",
      "72/175: Converting Node Type Relu\n",
      "73/175: Converting Node Type Conv\n",
      "74/175: Converting Node Type BatchNormalization\n",
      "75/175: Converting Node Type Relu\n",
      "76/175: Converting Node Type Conv\n",
      "77/175: Converting Node Type Add\n",
      "78/175: Converting Node Type BatchNormalization\n",
      "79/175: Converting Node Type Relu\n",
      "80/175: Converting Node Type Conv\n",
      "81/175: Converting Node Type BatchNormalization\n",
      "82/175: Converting Node Type Relu\n",
      "83/175: Converting Node Type Conv\n",
      "84/175: Converting Node Type BatchNormalization\n",
      "85/175: Converting Node Type Relu\n",
      "86/175: Converting Node Type Conv\n",
      "87/175: Converting Node Type Conv\n",
      "88/175: Converting Node Type Add\n",
      "89/175: Converting Node Type BatchNormalization\n",
      "90/175: Converting Node Type Relu\n",
      "91/175: Converting Node Type Conv\n",
      "92/175: Converting Node Type BatchNormalization\n",
      "93/175: Converting Node Type Relu\n",
      "94/175: Converting Node Type Conv\n",
      "95/175: Converting Node Type BatchNormalization\n",
      "96/175: Converting Node Type Relu\n",
      "97/175: Converting Node Type Conv\n",
      "98/175: Converting Node Type Add\n",
      "99/175: Converting Node Type BatchNormalization\n",
      "100/175: Converting Node Type Relu\n",
      "101/175: Converting Node Type Conv\n",
      "102/175: Converting Node Type BatchNormalization\n",
      "103/175: Converting Node Type Relu\n",
      "104/175: Converting Node Type Conv\n",
      "105/175: Converting Node Type BatchNormalization\n",
      "106/175: Converting Node Type Relu\n",
      "107/175: Converting Node Type Conv\n",
      "108/175: Converting Node Type Add\n",
      "109/175: Converting Node Type BatchNormalization\n",
      "110/175: Converting Node Type Relu\n",
      "111/175: Converting Node Type Conv\n",
      "112/175: Converting Node Type BatchNormalization\n",
      "113/175: Converting Node Type Relu\n",
      "114/175: Converting Node Type Conv\n",
      "115/175: Converting Node Type BatchNormalization\n",
      "116/175: Converting Node Type Relu\n",
      "117/175: Converting Node Type Conv\n",
      "118/175: Converting Node Type Add\n",
      "119/175: Converting Node Type BatchNormalization\n",
      "120/175: Converting Node Type Relu\n",
      "121/175: Converting Node Type Conv\n",
      "122/175: Converting Node Type BatchNormalization\n",
      "123/175: Converting Node Type Relu\n",
      "124/175: Converting Node Type Conv\n",
      "125/175: Converting Node Type BatchNormalization\n",
      "126/175: Converting Node Type Relu\n",
      "127/175: Converting Node Type Conv\n",
      "128/175: Converting Node Type Add\n",
      "129/175: Converting Node Type BatchNormalization\n",
      "130/175: Converting Node Type Relu\n",
      "131/175: Converting Node Type Conv\n",
      "132/175: Converting Node Type BatchNormalization\n",
      "133/175: Converting Node Type Relu\n",
      "134/175: Converting Node Type Conv\n",
      "135/175: Converting Node Type BatchNormalization\n",
      "136/175: Converting Node Type Relu\n",
      "137/175: Converting Node Type Conv\n",
      "138/175: Converting Node Type Add\n",
      "139/175: Converting Node Type BatchNormalization\n",
      "140/175: Converting Node Type Relu\n",
      "141/175: Converting Node Type Conv\n",
      "142/175: Converting Node Type BatchNormalization\n",
      "143/175: Converting Node Type Relu\n",
      "144/175: Converting Node Type Conv\n",
      "145/175: Converting Node Type BatchNormalization\n",
      "146/175: Converting Node Type Relu\n",
      "147/175: Converting Node Type Conv\n",
      "148/175: Converting Node Type Conv\n",
      "149/175: Converting Node Type Add\n",
      "150/175: Converting Node Type BatchNormalization\n",
      "151/175: Converting Node Type Relu\n",
      "152/175: Converting Node Type Conv\n",
      "153/175: Converting Node Type BatchNormalization\n",
      "154/175: Converting Node Type Relu\n",
      "155/175: Converting Node Type Conv\n",
      "156/175: Converting Node Type BatchNormalization\n",
      "157/175: Converting Node Type Relu\n",
      "158/175: Converting Node Type Conv\n",
      "159/175: Converting Node Type Add\n",
      "160/175: Converting Node Type BatchNormalization\n",
      "161/175: Converting Node Type Relu\n",
      "162/175: Converting Node Type Conv\n",
      "163/175: Converting Node Type BatchNormalization\n",
      "164/175: Converting Node Type Relu\n",
      "165/175: Converting Node Type Conv\n",
      "166/175: Converting Node Type BatchNormalization\n",
      "167/175: Converting Node Type Relu\n",
      "168/175: Converting Node Type Conv\n",
      "169/175: Converting Node Type Add\n",
      "170/175: Converting Node Type BatchNormalization\n",
      "171/175: Converting Node Type Relu\n",
      "172/175: Converting Node Type GlobalAveragePool\n",
      "173/175: Converting Node Type Flatten\n",
      "174/175: Converting Node Type Flatten\n",
      "175/175: Converting Node Type Gemm\n",
      "Translation to CoreML spec completed. Now compiling the CoreML model.\n",
      "Model Compilation done.\n"
     ]
    }
   ],
   "source": [
    "classes = [\"bengal_cat\",\n",
    "\"munchkin_cat\",\n",
    "\"persian_cat\",\n",
    "\"siamese_cat\",\n",
    "\"turkishangora_cat\"]\n",
    "\n",
    "ml_model = convert(model= onnx_file,\n",
    "                   mode='classifier',\n",
    "                   class_labels = classes,\n",
    "                   minimum_ios_deployment_target='12',\n",
    "                  preprocessing_args=args) # or minimum_ios_deployment_target = '13'\n",
    "\n",
    "ml_name = 'myresnet_cat.mlmodel'\n",
    "ml_model.save(ml_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "input {\n",
       "  name: \"data\"\n",
       "  shortDescription: \"MultiArray of shape (1, 1, 3, 224, 224). The first and second dimensions correspond to sequence and batch size, respectively\"\n",
       "  type {\n",
       "    multiArrayType {\n",
       "      shape: 3\n",
       "      shape: 224\n",
       "      shape: 224\n",
       "      dataType: FLOAT32\n",
       "    }\n",
       "  }\n",
       "}\n",
       "output {\n",
       "  name: \"resnetv21_dense1_fwd\"\n",
       "  type {\n",
       "    dictionaryType {\n",
       "      stringKeyType {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "output {\n",
       "  name: \"classLabel\"\n",
       "  type {\n",
       "    stringType {\n",
       "    }\n",
       "  }\n",
       "}\n",
       "predictedFeatureName: \"classLabel\"\n",
       "predictedProbabilitiesName: \"resnetv21_dense1_fwd\"\n",
       "metadata {\n",
       "  userDefined {\n",
       "    key: \"coremltoolsVersion\"\n",
       "    value: \"3.3\"\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Because it is more convenient to have input as Image in iOS app,\n",
    "# we then need to change the input type from MultiArray to Image\n",
    "import coremltools\n",
    "import coremltools.proto.FeatureTypes_pb2 as ft \n",
    "\n",
    "spec = coremltools.utils.load_spec(\"myresnet_cat.mlmodel\")\n",
    "\n",
    "input = spec.description.input[0]\n",
    "input.shortDescription = \"Image type with shape: 224 x 224 (RGB)\"\n",
    "input.type.imageType.colorSpace = ft.ImageFeatureType.RGB\n",
    "input.type.imageType.height = 224 \n",
    "input.type.imageType.width = 224\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, we need to add a scale layer to normalize image input into range [0..1]\n",
    "import copy\n",
    "\n",
    "# Get all layers of the model\n",
    "layers = spec.neuralNetworkClassifier.layers\n",
    "\n",
    "# We then make a deepcop the layers before delete it\n",
    "layers_copy = copy.deepcopy(layers)\n",
    "del layers[:]\n",
    "\n",
    "# Now, scale_layer becomes the first layer of the network\n",
    "scale_layer = layers.add()\n",
    "scale_layer.name = 'scale_layer'\n",
    "scale_layer.input.append('data')\n",
    "scale_layer.output.append('input_scaled')\n",
    "\n",
    "# Image scale for ImageNet\n",
    "\"\"\"\n",
    "IMAGE_NET_MEAN = [0.485, 0.456, 0.406]\n",
    "IMAGE_NET_STD = [0.229, 0.224, 0.225]\n",
    "\"\"\"\n",
    "#scale = 1.0 / (0.226 * 255.0)\n",
    "red_scale = 1.0 / (0.229 * 255.0)\n",
    "green_scale = 1.0 / (0.224 * 255.0)\n",
    "blue_scale = 1.0 / (0.225 * 255.0)\n",
    "\n",
    "#args = dict(is_bgr=False, red_bias = -(0.485 * 255.0) * red_scale  , green_bias = -(0.456 * 255.0) * green_scale,\n",
    "            #blue_bias = -(0.406 * 255.0) * blue_scale)\n",
    "\n",
    "params = scale_layer.scale\n",
    "params.scale.floatValue.extend([red_scale, green_scale, blue_scale]) \n",
    "params.shapeScale.extend([3,1,1]) # shape of the scale vector \n",
    "\n",
    "# now add back the rest of the layers\n",
    "layers.extend(layers_copy)\n",
    "\n",
    "# we need to change the input of the second layer to match the output of the scale_layer\n",
    "layers[1].input[0] = 'input_scaled'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input {\n",
      "  name: \"data\"\n",
      "  shortDescription: \"MultiArray of shape (1, 1, 3, 224, 224). The first and second dimensions correspond to sequence and batch size, respectively\"\n",
      "  type {\n",
      "    imageType {\n",
      "      width: 224\n",
      "      height: 224\n",
      "      colorSpace: RGB\n",
      "    }\n",
      "  }\n",
      "}\n",
      "output {\n",
      "  name: \"resnetv21_dense1_fwd\"\n",
      "  type {\n",
      "    dictionaryType {\n",
      "      stringKeyType {\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "output {\n",
      "  name: \"classLabel\"\n",
      "  type {\n",
      "    stringType {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "predictedFeatureName: \"classLabel\"\n",
      "predictedProbabilitiesName: \"resnetv21_dense1_fwd\"\n",
      "metadata {\n",
      "  userDefined {\n",
      "    key: \"coremltoolsVersion\"\n",
      "    value: \"3.3\"\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "# Get the model for testing\n",
    "mlmodel = coremltools.models.MLModel(spec)\n",
    "\n",
    "# Confirm the model has input as Image datatype\n",
    "print(mlmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output along channel at [0,0]:  {'resnetv21_dense1_fwd': {'bengal_cat': 0.7060546875, 'munchkin_cat': 1.912109375, 'persian_cat': -0.260009765625, 'siamese_cat': -3.39453125, 'turkishangora_cat': 0.75732421875}, 'classLabel': 'munchkin_cat'}\n"
     ]
    }
   ],
   "source": [
    "# Load an image to test your model\n",
    "img_path = './munchkin_cat.jpg'\n",
    "read_img = Image.open(img_path)\n",
    "# Resize image to the shape of your input image\n",
    "resize_img = read_img.resize((224, 224))\n",
    "resize_img.show()\n",
    "y = mlmodel.predict({'data': resize_img})\n",
    "print('output along channel at [0,0]: ', y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the modified model\n",
    "model_name = \"myresnet_cat_image(input).mlmodel\"\n",
    "coremltools.utils.save_spec(spec, model_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
